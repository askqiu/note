## 1，asn分析

https://bgp.he.net/search?search%5Bsearch%5D=tesla&commit=Search

cat asn.txt | asnmap | tee ipscope.txt

cat ipscope.txt | mapcidr | tee ips.txt

## 2反向whois

https://tools.whoisxmlapi.com/reverse-whois-search

注册信息：组织名，邮箱，发现关联域的方法

通过查看ssl证书，whois记录和dns条目来确定是不是厂商的资产

https://crt.sh/?q=TESLA%2C+INC.

## 3tlds扫描

对原本的www.example.FUZZ 进行爆破，获取这个厂商更广泛的业务以及某些区域的才有的业务，
扩大测试面

- Apex域名，就是根域名，例如www.tesla.com里面的Apex域名，即为tesla.com

## 4shodan

ssl.cert.subject.cn:*.tesla.com

ssl:.tesla.com

ssl:"Tesla Inc."

org:"Tesla Inc."

添加 !http.title:Invalid 语法过滤结果，只剩396个结果

Facet Analysis 也是一个很好用的功能，它把标题出现的次数从大到小进行了统计，我们可以根据它找到自己感兴趣的标题，然后先探索那部分资产

这个域名位于Akamai这个CDN上，有速率限制，用shodan的语法找出该域名的真实IP，以此绕过速率限制

## 5netlas

通过根域名提取子域名netlas download -d domain -c 10000 -i domain domain:"*.tesla.com" | jq -r .data.domain

通过组织名提取资产netlas download -d cert -c 10000 -i certificate.names 'certificate.subject.organization:"TESLA, INC."' | jq .data.certificate.names | tr -d "\"[],"| grep -Ev "^$"| sed '/*/d' | tr -d ' ' | sort -u

## 6子域名爬取

填上你能填上的各种api

amass   amass enum --passive -d tesla.com

subfinder -d dell.com -all

## 7子域名爆破

（情形1）puredns bruteforce all.txt tesla.com -r resolvers.txt   用那些特大字典

shuffledns -d tesla.com -w all.txt -r resolvers.txt -mode bruteforce

（情形2）根据直觉对某个域名觉得要花更多精力，可以对这个域名本身进行爆破，用几千到几万的字典去爆破一下看看有没有东西

有以下常见情形:
admin-fuzz.example.com
fuzz-admin.example.com
adminfuzz.example.com
fuzzadmin.example.com

ffuf -w words.txt -u https://sso-FUZZ.tesla.com -c -t 50 -mc all -fs   

或者生成一个新字典再用puredns进行解析sed 's/^/sso-/' words.txt > new_words.txt     然后puredns bruteforce new_words.txt tesla.com -r resolvers.txt

（情形3）对收集到的各种子域名添加常见的规则，在用解析工具解析，重复2到3次cat subs.txt | dnsgen - | puredns resolve --resolvers resolvers.txt

（情形4）最后一种和情形3有点像，但是又不完全一样，自动归纳出可以表示这个域名的正则表达式，然后自动推断出可能存在的子名，然后用解析工具进行DNS解析，重复刚才的操作，再次生成，再次解析，

python3 main.py -t example.com -f example.subs.txt -o example.output.txt

https://cramppet.github.io/regulator/index.html

## 8子域名劫持

9 s3桶劫持

两种情况  1：如果应用程序或DNS 记录中引用了存储桶名称，但存储桶本身未创建或已被删除，则攻击者可以创建同名存储桶，并可能拦截原始存储桶的数据

2：错误的权限：错误配置的存储桶权限可能允许未经授权的用户列出、读取、写入或删除存储桶的内容

cat subs-with-http.txt | nuclei -t nuclei-templates/http/takeovers/aws-bucket-takeover.yaml

如何判断是否有接管的可能性？访问域名且根目录为/的URL，看到提示“The specified bucket does not exist”代表有戏，但BucketName是亚马逊域名的话，可以跳过，不是的话，可以一试。运行以下命令检查DNS记录，获取接管所需的信息(悬空域和存储桶名称)：dig CNAME 存储桶名称

## 10，端口扫描

Naabu用于初始端口扫描先检查一下，然后调用 Nmap 进行服务识别，以获取更详细的扫描信息

naabu -list lists.txt -p - -exclude-ports 80,443,21,22,25 -rate 20000 -c 500 -retries 2 -warm-up-time 1 -silent -nmap-cli 'nmap -sV -oX scan.xml'

-exclude-ports 80,443,21,22,25：排除这些端口

-rate 20000：默认的过低

-c 500：默认25线程还是有点少
-retries 2：默认重连3次太多了，两次就行

## 11，测活，技术识别

但在技术识别之前，先进行测活，把之前收集的所有的ip列表，域名列表，以及这些ip/域名开放的端⼝列表进行测活

- 测活：
cat subs.txt | httpx | tee subs_live.txt 或者 cat subs.txt | httpx -nf | tee subs_live.txt
- Nuclei
cat subs_live.txt | nuclei -t http/technologies/
- webanalyze
./webanalyze -host example.com -crawl 1 -output csv

## 12，技术栈识别

- Builtwith https://builtwith.com/relationships/tesla.com

用于了解网站关联性情况，识别某网站用的技术找使用相同技术的其他网站，根据相同技术的使用情况显示相关网站，这些网站可能也属于这个厂商的资产

## 13，favicon分析

- Favicon 分析现代浏览器会在网页标题左侧显示一个小图像/图标，该图标称为favicon.ico，获取 favicon.ico 并计算其哈希值，根据icon hash对域/子域/IP 进行排序

cat subs_live.txt | python3 favfreak.py -o output

用fofa可以快速获取厂商的Favicon Hash后在shodan里面搜索从fofa 那里获取的Favicon Hash

## 14，截屏分析

Gowitness使用Headless Chrome获取网站的屏幕截图
1. 先用gowitness file -f urls.txt --threads 50这条命令，对urls.txt里面的url进行截屏
2. 运行gowitness report serve -a vps的ip:端口启动报告服务器

## 17，爬虫

- Burp Suite Pro （点点点就完事了）创建项目，保留，刨齿机记录流量

- 勾上Use advances scope control（target里的scope）然后设置好相应的关键词在浏览器批量打开(Copy All Urls 插件)子域名(方便演示只用了700+子域遇到可以注册的域名，去注册以及登录，然后点点点那些访问的功能

- 勾上 Show only in-scope items（target 的site map的功能）

- Hakrawler
  cat subs_live.txt | hakrawler -subs > hakrawler_out.txt   输出结果作为输入，进行两三次

- Katana
  cat subs_live.txt | katana -sc -kf robotstxt,sitemapxml -jc -c 50 > katana_out.txt

- Gospider
  gospider -S subs_live.txt -o gs_output -c 50 -d 2 --other-source --subs --sitemap --robots

  --other-source
  添加这个标记从其他数据源获取数据
  比如：
  Archive.org
  CommonCrawl.org
  VirusTotal.com
  AlienVault.com

- Gau  脏数据很多，需要去重以及提取关键url在合并
  cat subs_live.txt | gau > gau_out.txt

- Oxdork
  oxdork "site:yahoo.com" -c 100

  Google dork 是非常强有力的工具，
  但是我们无法访问google.com ，那么
  如何解决这个问题呢？
  解决方法很简单，在阿里云购买VPS
  使用oxdork 执行Google dork
  运行oxdork "site:yahoo.com" -c 100
  这个命令就可以获得site:yahoo.com 的Google dork 结果
  但是多次运行以后ip会被谷歌禁止，需要等待几个小时以后才能重新使用
  这意味着无法对多个子域名批量执行Google dork，你可以尝试自己魔改代码

- 以上工具都是通过域名生成url

直接访问https://watchdocs.indriverapp.com/返回401，所以直接针对根路径的常规爬虫都无效

为什么爬虫这么重要，因为出洞的前提是找到可能出现漏洞的路径

爬虫作用是给你一个测试的入口点，但是不能完全依赖它，比如那三个XSS报告，第一个XSS报告有非常惊人的重复率，因为不少人是自动化出的这个洞，第二个和第三个重复率就大大降低了，因为需要一点手动分析；又比如那个盲SQL注入的报告，直接对id.indrive.com进行爬虫是不可行的(直接访问是404 NOT FOUND)，直接手动测试promo.indrive.com不依赖工具只靠bp点点点同样也是不可行的，因为你会感觉这是一个静态网站，没有什么可以测试的，通过时光机找到一个入口点，再手动分析，才能发现这个漏洞，这也是为啥扫描器经常扫不出漏洞的原因，因为它没有找到那个URL, 如果你把那个有漏洞的URL丢给它，它大概率还是可以扫出来的信息的收集往往不是独立的，而是多个工具和多个手法相互作用的结果

## 18，目录爆破

目录爆破的作用
- 隐蔽功能发现
- API 文档泄露
- 备份文件泄露
- 错误配置
- 403绕过
- 其他

- 字典获取
https://wordlists.assetnote.io/
https://github.com/danielmiessler/SecLists/tree/master/Discovery/Web-Content
https://github.com/orwagodfather/WordList
- 不知道如何挑选字典可以先试一下下面的通用字典
https://github.com/danielmiessler/SecLists/blob/master/Fuzzing/403/403.md (403绕过字典)
https://github.com/danielmiessler/SecLists/blob/master/Fuzzing/fuzz-Bo0oM.txt(4k 量级)
https://github.com/Bo0oM/fuzz.txt/blob/master/fuzz.txt (5k 量级)
https://github.com/orwagodfather/WordList/blob/main/fuzz.txt (22k 量级)
https://github.com/thehlopster/hfuzz/blob/master/hfuzz.txt (18w 量级)
https://github.com/six2dez/OneListForAll (多个量级)

把之前爬取收集的所有url，把所有结果去重后保留在一个文件，这些字典记得保持更新，是一个循环迭代的过程，这些字典可以作为以后测试每个子域名的字典，因为是同一个厂商，所以这个子域名的路径在另外一个子域名可能也有用 ，参数同理

- 获取路径字典
cat urls.txt | unfurl paths | sed 's/^.//' | sort -u | egrep -iv
"\.(jpg|swf|mp3|mp4|m3u8|ts|jpeg|gif|css|tif|tiff|png|ttf|woff|woff2|ico|pdf|svg|txt|js)" | tee
paths.txt
- 获取参数字典
cat urls.txt | unfurl keys | sort -u | tee params.txt

- 对每个子域名的每个路径都应该爆破
举个例子，有这么一个URL，https://www.█████/daip/messagebroker/amf
那么爆破的时候应该对这个URL每个目录进行目录爆破
https://www.█████/daip/messagebroker/{爆破}
https://www.█████/daip/{爆破}
https://www.█████/{爆破}
这种情况下使用小字典，大小在100到500之间，不建议超过500，你可以根据你的个人习惯
进行配置，比如API 文档泄露，备份文件泄露啥的

- Burp Suite Pro Intruder 模块（不要勾选url编码）
- 对Status code进行排序
  利用Render功能对响应进行检查

以#2051931演示Intruder 模块如何发现
以各种爬虫工具对promo.indrive.com 爬取URL爬虫爬取到某个URL，这个URL，距离发现漏洞还有不少的距离需要从这些被记录的URL找到可能会出现漏洞的那个

工具 feroxbuster --url https://promo.indrive.com/ -w paths.txt    如果再次运行，就会出现下图所示场景，被ddos-guard拦截了

## 19，参数收集和爆破

上面有讲从url提取参数

从响应内容提取参数，用到GAP-Burp-Extension插件

用报告#2015074 检测插件的实测效果，已知Oxdork 可以跑出下面的URL
https://watchdocs.indriverapp.com/webview/v1?phone=79644195058&token=4b152cc4ed292ceb10be490dd0a9e297&service=appcity
打开Burp suite, 设置好项目范围，点击上面的链接谷歌搜出来的链接是没有jwt这个参数的

插件成功为我们搜集到了这个参数，但是需要注意的是，在实际挖洞的过程需要不断更新我们的参数字典，这是一个循环迭代的过程

参数爆破

隐藏参数的识别往往是通过状态码的变化，响应长度的变化，页面是不是反射了这个参数等等差异分析识别出来的

- Param-Miner 是Burp Suite 比较常用的参数爆破插件
- Arjun 是比较常用的参数爆破命令行工具(自动化可以试试，手动挖的时候不建议用)
- Burp Suite Pro Intruder 模块 是比较适合用来发现和xss相关的参数

-
intruder在使用这个模块之前，我们需要先按照前面的方法收集好参数，然后对参数进行一点点处理简单来说，一次爆破一个参数效率往往很低而反射XSS只需要检查页面是不是反射了参数值，所以检测逻辑其实很简单，看看页面有没有回显参数值就行，这样的话一次性爆破50个数也是没有问题的(如果测试域名显示50个参数长度过大可以调整成30个或者20个)

代码如右图所示，非常简单的小代码n是指定一次性爆破多少个参数test可以自由调整![5fc721e7d5a677f5e2274e21a7a1c62](C:\Users\三哥佬\Documents\WeChat Files\wxid_00iq5cy38fkg22\FileStorage\Temp\5fc721e7d5a677f5e2274e21a7a1c62.png)

设置好后开始爆破，（这里有三张图）

从图中可以看见识别出来了jwt 参数，在实际的测试中还需要注意检查特殊符号有没有被转义同时应该多个路径一起批量爆破以此提高测试效率![bb6f7dee5368d90b8084cb388a24dd2](C:\Users\三哥佬\Documents\WeChat Files\wxid_00iq5cy38fkg22\FileStorage\Temp\bb6f7dee5368d90b8084cb388a24dd2.png![cdd0cb1be1e49bc4ba8f47b86c45b1e](C:\Users\三哥佬\Documents\WeChat Files\wxid_00iq5cy38fkg22\FileStorage\Temp\cdd0cb1be1e49bc4ba8f47b86c45b1e.png)

![bb6f7dee5368d90b8084cb388a24dd2](C:\Users\三哥佬\Documents\WeChat Files\wxid_00iq5cy38fkg22\FileStorage\Temp\bb6f7dee5368d90b8084cb388a24dd2.png)

## 20 javascript分析

jsscan     for i in $(cat all_js.txt); do python3 /root/tools/JSSCAN/JSSCAN.py -u $i -d 2 >> JSSCAN.log; done

## 22威胁建模

- 威胁建模，针对信息收集的结果，构想可行的测试方案
通过前面的部分，想必你已经了解了什么是信息收集在经过一系列的信息收集，我们获取了目标的子域名和ip，获取了目标的各种URL，还生成了针对目标的自定义字典，如果你进行github信息收集，可能还能搜集到目标泄露的账号密码，虽然我们收集了一系列信息，但是摆在我们面前的还有一个很头疼的问题，我们现在有数万，10几万，甚至有时候是几十万的URL，我们如何处理这些URL，这些URL 里面也许就藏着有漏洞的URL，或者这些URL里面都没有漏洞，但是可能是漏洞URL的入口点URL(像之前提到的promo.indrive.com=>id.indrive.com)我们不可能一个一个打开这些URL，因为这是不现实的，这也是我们接下来要讨论的话题如果说信息收集是收集到目标相关的资产信息，那么威胁建模就是从这些收集的信息再逆推回去找出可能的测试方案以及有可能有漏洞的子域名

首先可以过滤关键字，比如grep asp，这样搜索出来的可以优先考虑sql注入和xss，同理grep php

同理还可以grep -E “admin|login|signup|register|registration|password|testuser|testing|firebase”获取管理面板，登陆面板等

grep -E “api|apidoc|internal|secret|swagger”还可以这样获取api接口

同理还可以grep -E “dev|stage|stg|staging|prod|qa”获取开发，测试，暂存环境

除此之外平时应该自己注意收集一些关键词，比如下面的报告的order关键词grep “order”获取订单相关功能

直接访问这个域名没有什么特别的东西通过Bing （dork）搜索 获得更多的信息

![afebb051dbe14cec74484b1b4e0c920](C:\Users\三哥佬\Documents\WeChat Files\wxid_00iq5cy38fkg22\FileStorage\Temp\afebb051dbe14cec74484b1b4e0c920.png)

![44eed044b88d4116d5209b6c6926ddf](C:\Users\三哥佬\Documents\WeChat Files\wxid_00iq5cy38fkg22\FileStorage\Temp\44eed044b88d4116d5209b6c6926ddf.png)

## 23信息收集框架

列出两个常用的：
- reconFTW
- reNgine
主要使用它们的子域名收集和截图相关的功能，不指望它可以扫出什么漏洞，大部分挖洞的过程应该在Burp suite手动进行。而且大部分的时候，我会重新进行目录爆破，因为需要生成自定义字典以适配目标厂商，同时设置适当的过滤规则防止太多误报的输出

## 24总结

1，子域名更容易出洞

2，记得对所有主机进行端口扫描，许多高危严重都是容易出现在非标准端口

3，如果手机app在范围，也要测试，因为更容易出现越权

4，可以检查厂商员工的领英，检查他们的github账号，说不定会泄露密码或者token

5. 不能只依赖命令行工具爬⾍，其实它们根本靠不住，打开你的Burp Suite, 对站点的功能进行访
问
6. 除了访问站点的功能以外，目录爆破也是必要的， 通过它可以找到某些隐藏的功能，这些功能可能是网站开发者不想让你看见的，可能是你常规点点点浏览网站无法看见的(像https://promo.indrive.com/ 那个网站的例子)
7. 对海外src的厂商做好信息收集，只要它不是那种难度比较大的厂商或者已经上线很久的厂商，那么很多时候都会发现漏洞